{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CLAH Image Analysis","text":"<p>A comprehensive suite of Python programs for 2-photon calcium imaging analysis, with support for 1-photon imaging in progress. Best to use on a local server, with a GPU for faster processing and data stored on a drive(s) separate from the root mount.</p>"},{"location":"#overview","title":"Overview","text":"<p>CLAH Image Analysis provides tools for:</p> <ul> <li>2-photon imaging analysis</li> <li>Motion correction and segmentation</li> <li>Cell registration</li> <li>Unit analysis</li> <li>Calcium imaging processing</li> </ul>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Installation Guide</li> <li>Order of Operations</li> <li>Structure for path names</li> <li>Command Line Tools</li> <li>Graphical User Interfaces</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Follow the Installation Guide to set up your environment</li> <li>Review the Order of Operations to understand the workflow</li> <li>Check the Structure for path names to organize your data</li> <li>Choose between Command Line Tools or Graphical User Interfaces based on your needs.</li> </ol>"},{"location":"1_installation/","title":"Installation Guide","text":"<p>Can be used as a library on all OS's, but to properly use the package entirely, best to use on a machine running a Debian-based distribution with systemd and NVIDIA drivers.</p>"},{"location":"1_installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Anaconda<ul> <li>still testing on more lightweight python environment/package managers</li> <li>base install works with uv</li> </ul> </li> <li>To use with a GPU:<ul> <li>a machine running Ubuntu or Windows<ul> <li>can use Windows Subsystem for Linux (WSL)</li> <li>would recommend Pop!_OS for NVIDIA drivers</li> <li>use a non-Debian-based Linux distro at your own risk</li> </ul> </li> <li>CUDA<ul> <li>for Ubuntu (CUDA website)</li> <li>for Windows (CUDA website)</li> <li>for WSL (CUDA website)</li> <li>for Ubuntu/WSL (handy guide on github)</li> </ul> </li> </ul> </li> <li>To run web applications as persistent background services:<ul> <li>systemd</li> <li>TMUX</li> </ul> </li> </ul>"},{"location":"1_installation/#dependencies","title":"Dependencies","text":"<ul> <li>CaImAn</li> <li>ROICaT</li> <li>scikit-cuda (required for GPU)</li> <li>SQLJobScheduler</li> </ul>"},{"location":"1_installation/#installation","title":"Installation","text":""},{"location":"1_installation/#development-mode-recommended","title":"Development Mode (Recommended)","text":"<pre><code># Clone CLAH Image Analysis repository\ngit clone https://github.com/thicclatka/CLAH_IA.git\n\n# cd to CLAH IA directory\ncd /path/to/CLAH_IA\n\n# create conda environment\n# yaml here is based on caiman's\nconda env create -f environment.yml -n caiman\nconda activate caiman\n\n# Install package\n# will also install dependencies listed above\npip install -e \"/path/to/CLAH_IA[all]\"\n</code></pre>"},{"location":"1_installation/#library-mode","title":"Library Mode","text":"<pre><code># to use as a library without GPU support\npip install git+https://github.com/thicclatka/CLAH_IA\n\n# to use as a library with GPU support\npip install git+https://github.com/thicclatka/CLAH_IA[all]\n</code></pre>"},{"location":"1_installation/#persistent-web-application-setup","title":"Persistent web application setup","text":"<p>If program is running on a machine running Linux with systemd, you can set up the web applications to run as system services. This allows them to start automatically on boot and be managed by systemd.</p> <p>To do this, navigate to the root directory of the <code>CLAH_IA</code> repository and run the <code>setup.sh</code> script:</p> <pre><code>cd /path/to/CLAH_IA\nchmod +x setup.sh\n./setup.sh\n</code></pre> <p>This script will typically perform the following actions:</p> <ul> <li>Create systemd service files for the web applications.</li> <li>Store files in config directory (<code>~/.clah_ia/</code>)</li> <li>Provide instructions on:<ul> <li>How to reload systemd daemon</li> <li>Start the services</li> <li>Enable services to start on boot up</li> </ul> </li> </ul> <p>Make sure to inspect the SystemdServices directory in the repo if you want to understand the exact commands being run or if you need to customize the setup.</p>"},{"location":"2_order-of-operations/","title":"Order of Operations","text":""},{"location":"2_order-of-operations/#terms","title":"Terms","text":"<ul> <li>Single session: directories where each subdirectory holds a single session of data</li> <li>Multisession: directories where each subdirectory holds multiple sessions of data</li> </ul>"},{"location":"2_order-of-operations/#single-session","title":"Single session","text":"<ol> <li>Moco2segDict (M2SD)</li> <li>quickTuning (QT) (need .tdml to run)</li> </ol>"},{"location":"2_order-of-operations/#multisession","title":"Multisession","text":"<ol> <li>M2SD -&gt; QT (Using data directory with single session subdirectories)</li> <li>wrapMultSessStruc</li> <li>cellRegistrar_wROICaT (Using data directory with multisession subdirectories from here)</li> <li>PostCR_CueCellFinder</li> <li>CR_CI_collater</li> </ol> <p>If QT cannot be used:</p> <ol> <li>M2SD</li> <li>wrapMultSessStruc</li> <li>cellRegistrat_wROICaT</li> </ol>"},{"location":"3_structure-folder-path-names/","title":"Structure for folder/path names","text":""},{"location":"3_structure-folder-path-names/#single-session","title":"Single session","text":"<p>/ path / to / dir / [DIR_NAME_FT_EXPERIMENT_KEYWORDS] / [DATE]_[SUBJECT_ID]_[EXPERIMENT]</p>"},{"location":"3_structure-folder-path-names/#dir_name_ft_experiment_keywords","title":"[DIR_NAME_FT_EXPERIMENT_KEYWORDS]","text":"<ul> <li>is the name of the directory holding the experiment data</li> <li>e.g. eOPN3_CA3_2408 or Alzheimers_20240912-30_CA3</li> <li>there is no requirement for a specific format, but try to be consistent with a set of experiments</li> </ul>"},{"location":"3_structure-folder-path-names/#date","title":"[DATE]","text":"<ul> <li>format: YYMMDD (e.g. 240912 for September 12, 2024)</li> </ul>"},{"location":"3_structure-folder-path-names/#subject_id","title":"[SUBJECT_ID]","text":""},{"location":"3_structure-folder-path-names/#experiment","title":"[EXPERIMENT]","text":"<ul> <li>is the experiment name</li> <li>e.g. cueShiftOmitIAA-001</li> <li>no requirement for a specific format, but try to be consistent with a set of experiments</li> </ul> <p>NOTE: Underscores are required between the subject ID, and experiment name</p>"},{"location":"3_structure-folder-path-names/#multisession","title":"Multisession","text":"<p>/ path / to / dir / _MS_[DIR_NAME_FT_EXPERIMENT_KEYWORDS]_[BRAIN_REGION] / [SUBJECT_ID]_[NUM_SESSIONS]</p>"},{"location":"3_structure-folder-path-names/#_ms_","title":"_MS_","text":"<ul> <li>prefix for multisession directories</li> <li>notes each folder within directory contains multSessSegStruc (see wrapMultSessStruc)</li> <li>automatically prepended by wrapMultSessStruc</li> </ul>"},{"location":"3_structure-folder-path-names/#dir_name_ft_experiment_keywords_1","title":"[DIR_NAME_FT_EXPERIMENT_KEYWORDS]","text":"<ul> <li>recommended to use words like OPTO, eOPN3, AD (Alzheimers), Ag (Aged)</li> <li>if output_folder is not specified (by default, it is not), wrapMultSessStruc will prompt user to input experiment keywords for output folder name</li> <li>these keywords are required in order to trigger certain conditions to run in PostCR_CueCellFinder and CR_CI_collater</li> </ul>"},{"location":"3_structure-folder-path-names/#brain_region","title":"[BRAIN_REGION]","text":"<ul> <li>if output_folder is not specified (by default, it is not), wrapMultSessStruc will prompt user to input brain region</li> <li>between CA3 &amp; DG</li> <li>this is required since it is used to set certain parameters for CellRegistrar_wROICaT</li> </ul>"},{"location":"3_structure-folder-path-names/#subject_id_num_sessions","title":"[SUBJECT_ID]_[NUM_SESSIONS]","text":"<ul> <li>created automatically by wrapMultSessStruc</li> </ul> <p>NOTE: Underscores are required between each element of the folder name</p>"},{"location":"CLIs/CLI_index/","title":"Command Line Tools","text":"<p>This directory contains documentation for the various command-line interface (CLI) tools available in CLAH Image Analysis.</p>"},{"location":"CLIs/CLI_index/#cli-categories","title":"CLI Categories","text":""},{"location":"CLIs/CLI_index/#tifstackfunc","title":"tifStackFunc","text":"<p>Core tools for processing raw imaging data:</p> <ul> <li>Motion correction of calcium imaging movies</li> <li>Segmentation of cells using CNMF</li> <li>Generation of segmented dictionaries (segDict)</li> <li>Output includes motion-corrected movies, component evaluations, and spatial maps</li> </ul>"},{"location":"CLIs/CLI_index/#unit-analysis","title":"Unit Analysis","text":"<p>Tools for analyzing individual units and their responses (set up mostly for 2P experiments currently):</p> <ul> <li>Quick Tuning: Analysis of cell responses to behavioral cues</li> <li>Multi-session Structure Wrapper: Combines data across sessions</li> <li>Post Cell Registrar Cue Cell Finder: Identifies cells responding to specific cues</li> </ul>"},{"location":"CLIs/CLI_index/#cell-registration","title":"Cell Registration","text":"<p>Tools for registering cells across sessions:</p> <ul> <li>Cell Registrar with ROICaT: Aligns cells across multiple sessions</li> <li>Cluster Info Collater: Aggregates and analyzes registration results</li> </ul>"},{"location":"CLIs/cellRegistration/","title":"Cell Registration","text":""},{"location":"CLIs/cellRegistration/#cell-registrar-wroicat","title":"Cell Registrar w/ROICaT","text":""},{"location":"CLIs/cellRegistration/#crwroi-input","title":"CRwROI Input","text":"<ul> <li>multSessSegStruc</li> </ul>"},{"location":"CLIs/cellRegistration/#crwroi-output","title":"CRwROI Output","text":"<ul> <li>json with cluster info (_cluster_info_ROICaT.json)</li> <li>results dictionary (_results_ROICaT)</li> <li>ROICaT rundata dictionary (_rundata_ROICaT)</li> <li>json with CR_wROI parameters (CRwROIparams.json)</li> <li>Figures (stored in /path/to/multSessSegStruc/_Figures_ROICaT)</li> </ul>"},{"location":"CLIs/cellRegistration/#crwroi-cli","title":"CRwROI CLI","text":"<pre><code>usage: cellRegistrar_wROICaT.py   [-h] [-p PATH] [-s2p SESS2PROCESS]\n                                  [-sf SESSFOCUS] [-G USEGPU] [-v VERBOSE]\n\nRun CellRegistar with ROICaT with command line arguments.\n\noptions:\n  -h, --help            show this help message and exit\n  -p PATH, --path PATH  Path to the data directory (e.g. /path/to/data).\n                        Default will prompt user to choose path.\n                        NOTE: Pick directory which holds session folders.\n                              Do not pick/set a session folder.\n  -s2p SESS2PROCESS, --sess2process SESS2PROCESS\n                        List of sessions to process. Write in format '1,2,3', '1-3',\n                        or '1,2-5' to select by specific session number.\n                        Input all or ALL to process all eligible sessions that are\n                        available within the set path.\n                        Default will prompt user to choose.\n  -sf SESSFOCUS, --sessFocus SESSFOCUS\n                        Set number of sessions to analyze.\n                        Default is None, which will analyze all sessions found within\n                        multSessSegStruc.\n  -G USEGPU, --useGPU USEGPU\n                        Whether to use GPU for ROICaT functions. Default is True\n  -v VERBOSE, --verbose VERBOSE\n                        Whether to print verbose output for ROICaT functions.\n                        Default is True\n</code></pre>"},{"location":"CLIs/cellRegistration/#cell-registrar-cluster-info-collater-cr_ci_collater","title":"Cell Registrar Cluster Info Collater (CR_CI_collater)","text":""},{"location":"CLIs/cellRegistration/#cicoll-input","title":"CICOLL Input","text":"<ul> <li>json with cluster info (_cluster_info_ROICaT.json)</li> </ul>"},{"location":"CLIs/cellRegistration/#cicoll-output","title":"CICOLL Output","text":"<ul> <li>csv with cluster info for all subjects (/path/to/_MS_dir/~GroupData/ClusterInfo_all.csv)</li> <li>csv with cluster info averages by group (/path/to/_MS_dir/~GroupData/ClusterInfo_means.csv)</li> </ul>"},{"location":"CLIs/cellRegistration/#cicoll-cli","title":"CICOLL CLI","text":"<pre><code>usage: CR_CI_collater.py [-h] [-p PATH] [-s2p SESS2PROCESS] [-4p FORPRES]\n\nRun CellRegistrar Cluster Info Collater with command line arguments.\n\noptions:\n  -h, --help            show this help message and exit\n  -p PATH, --path PATH  Path to the data directory (e.g. /path/to/data).\n                        Default will prompt user to choose path.\n                        NOTE: Pick directory which holds session folders.\n                              Do not pick/set a session folder.\n  -s2p SESS2PROCESS, --sess2process SESS2PROCESS\n                        List of sessions to process. Write in format '1,2,3', '1-3',\n                        or '1,2-5' to select by specific session number.\n                        Input all or ALL to process all eligible sessions that are\n                        available within the set path.\n                        Default will prompt user to choose.\n  -4p FORPRES, --forPres FORPRES\n                        Whether to export .svg for figures in addition to the usual\n                        png output. Default is False.\n</code></pre>"},{"location":"CLIs/tifStackFunc/","title":"Motion Correction &amp; Segmentation (CLI)","text":""},{"location":"CLIs/tifStackFunc/#motion-correction-to-segmented-dictionary-moco2segdict","title":"Motion Correction to Segmented Dictionary (Moco2segDict)","text":""},{"location":"CLIs/tifStackFunc/#input","title":"Input","text":"<ul> <li>raw movie stored in H5 file (2p) or ISXD (1p)</li> </ul>"},{"location":"CLIs/tifStackFunc/#output","title":"Output","text":"<ul> <li>tifs of average activity</li> <li>evalution of segmented components (CountourPlot_CompEval.png)</li> <li>mmaps of motion corrected movie</li> <li>motioned corrected movie stored in H5 (H5 file with _eMC tag)</li> <li>segmented dictionary (segDict) as .pkl &amp; .h5</li> <li>see section below for non-default output options</li> </ul>"},{"location":"CLIs/tifStackFunc/#cli","title":"CLI","text":"<pre><code>usage: MoCo2segDict.py  [-h] [-p PATH] [-s2p SESS2PROCESS] [-mc MOTION_CORRECT]\n                        [-sg SEGMENT] [-n4mc N_PROC4MOCO] [-n4cnmf N_PROC4CNMF]\n                        [-cat CONCATENATE]\n\nRun Moco2segDict with command line arguments.\n\noptions:\n  -h, --help            show this help message and exit\n  -p PATH, --path PATH  Path to the data directory (e.g. /path/to/data). Default will prompt user to choose path. NOTE: Pick directory which holds session folders; do not pick/set a session folder.\n  -s2p SESS2PROCESS, --sess2process SESS2PROCESS\n                        List of sessions to process. Write in format '1,2,3', '1-3', or '1,2-5' to select by specific session number. Input all or ALL to process all eligible sessions that are available within\n                        the set path. Default will prompt user to choose.\n  -fs FROM_SQL, --from_sql FROM_SQL\n                        Whether script is being run from SQL scheduler. Default is False.\n  -mc MOTION_CORRECT, --motion_correct MOTION_CORRECT\n                        Whether to perform motion correction. Default is false. (e.g. -mc y, -mc yes, -mc true to enable)\n  -sg SEGMENT, --segment SEGMENT\n                        Whether to perform segmentation. Default is false. (e.g. -seg y, -seg yes, -seg true to enable)\n  -n4mc N_PROC4MOCO, --n_proc4MOCO N_PROC4MOCO\n                        How many processors to use for motion correction. Default is 26 processes\n  -n4cnmf N_PROC4CNMF, --n_proc4CNMF N_PROC4CNMF\n                        How many processors to use for CNMF segmentation. Default is using all available processes.\n  -cat CONCATENATE, --concatenate CONCATENATE\n                        Concatenate H5s into a single H5 before motion correction, but create 2 segDicts. ONLY USE THIS TO COMBINE THE RESULTS FOR THE SAME SUBJECT ID ACROSS 2 SESSIONS.\n  -mci MC_ITER, --mc_iter MC_ITER\n                        Number of iterations for motion correction. Default is 1. WARNING: this is not the same as the number of iterations for rigid motion correction (niter_rig) within caiman and it can add\n                        to the total processing time.\n  -ow OVERWRITE, --overwrite OVERWRITE\n                        Overwrite existing files (segDicts, sqz_H5s, tifs, mmaps, etc). Default is False.\n  -cm COMPUTE_METRICS, --compute_metrics COMPUTE_METRICS\n                        Calculate motion correction metrics. Default is False.\n  -crp USE_CROPPER, --use_cropper USE_CROPPER\n                        Use the cropping utility for 1photon data (.isxd files). Default is False.\n  -sc SEPARATE_CHANNELS, --separate_channels SEPARATE_CHANNELS\n                        Whether to motion correct channels separately. Only applicable for 2photon data with 2 channels. Default is False.\n  -ers EXPORT_POSTSEG_RESIDUALS, --export_postseg_residuals EXPORT_POSTSEG_RESIDUALS\n                        Whether to export the post-segmentation residuals as a video file. Default is False.\n</code></pre>"},{"location":"CLIs/unitAnalysis/","title":"Unit Analysis","text":""},{"location":"CLIs/unitAnalysis/#quick-tuning","title":"Quick Tuning","text":""},{"location":"CLIs/unitAnalysis/#qt-input","title":"QT Input","text":"<ul> <li>segmented dictionary (segDict)</li> <li>treadmill/behavior log/json file (.tdml)</li> </ul>"},{"location":"CLIs/unitAnalysis/#qt-output","title":"QT Output","text":"<ul> <li>treadmill behavior dictionary (treadBehDict)</li> <li>lap info dictionary (lapDict)</li> <li>Cue Cell info &amp; arrays dictionary (CueCellFinderDict)</li> <li>cueShiftStruc</li> <li>Figures (stored in /path/to/segDict/Figures)</li> </ul>"},{"location":"CLIs/unitAnalysis/#qt-cli","title":"QT CLI","text":"<pre><code>usage: quickTuning.py   [-h] [-p PATH] [-s2p SESS2PROCESS] [-f FPS] [-sdt SDTHRESH]\n                        [-to TIMEOUT] [-ow OVERWRITE] [-pp TOPLOTPKS] [-4p FORPRES]\n                        [-cat CONCATCHECK]\n\nRun quickTuning with command line arguments.\n\noptions:\n  -h, --help            show this help message and exit\n  -p PATH, --path PATH  Path to the data directory (e.g. /path/to/data).\n                        Default will prompt user to choose path.\n                        NOTE: Pick directory which holds session folders.\n                              Do not pick/set a session folder.\n  -s2p SESS2PROCESS, --sess2process SESS2PROCESS\n                        List of sessions to process. Write in format '1,2,3', '1-3',\n                        or '1,2-5' to select by specific session number.\n                        Input all or ALL to process all eligible sessions that are\n                        available within the set path.\n                        Default will prompt user to choose.\n  -fw FRAMEWINDOW, --frameWindow FRAMEWINDOW\n                        Window size (in frames) used for smoothing for the event/peak\n                        detection. Default is 15.\n  -sdt SDTHRESH, --sdThresh SDTHRESH\n                        Threshold multiplier for event/peak detection based on the standard\n                        deviation of the signal's derivative.\n                        Default is 3.\n  -to TIMEOUT, --timeout TIMEOUT\n                        Minimum distance between detected peaks/events in seconds.\n                        Default is 3.\n  -ow OVERWRITE, --overwrite OVERWRITE\n                        Overwrite existing files\n                        (e.g. pkl &amp; mat for treadBehDict, lapDict, cueShiftStruc)\n  -pp TOPLOTPKS, --toPlotPks TOPLOTPKS\n                        Whether to plot results from pks_utils. Default is False.\n  -4p FORPRES, --forPres FORPRES\n                        Whether to export .svg for figures in addition to the usual\n                        png output. Default is False.\n</code></pre>"},{"location":"CLIs/unitAnalysis/#wrapmultsessstruc","title":"WrapMultSessStruc","text":""},{"location":"CLIs/unitAnalysis/#wmss-input","title":"WMSS Input","text":"<ul> <li>cueShiftStruc</li> </ul>"},{"location":"CLIs/unitAnalysis/#wmss-output","title":"WMSS Output","text":"<ul> <li>multSessSegStruc (location is based on -output_folder parameter)</li> </ul>"},{"location":"CLIs/unitAnalysis/#wmss-cli","title":"WMSS CLI","text":"<pre><code>usage: wrapMultSessStruc.py [-h] [-p PATH] [-s2p SESS2PROCESS] [-out OUTPUT_FOLDER]\n\nRun wrapMultSessStruc with command line arguments.\n\noptions:\n  -h, --help            show this help message and exit\n  -p PATH, --path PATH  Path to the data directory (e.g. /path/to/data).\n                        Default will prompt user to choose path.\n                        NOTE: Pick directory which holds session folders.\n                              Do not pick/set a session folder.\n  -s2p SESS2PROCESS, --sess2process SESS2PROCESS\n                        List of sessions to process. Write in format '1,2,3', '1-3',\n                        or '1,2-5' to select by specific session number.\n                        Input all or ALL to process all eligible sessions that are\n                        available within the set path.\n                        Default will prompt user to choose.\n  -out OUTPUT_FOLDER, --output_folder OUTPUT_FOLDER\n                        Path for the output of pkl &amp; mat files for multSessSegStruct.\n                        Default is None, which prompts user to input experiment keywords\n                        &amp; brain region to create output folder name.\n                        All output paths will be prepended with '_MS_'.\n</code></pre>"},{"location":"CLIs/unitAnalysis/#post-cell-registrar-cue-cell-finder-postcr_cuecellfinder","title":"Post Cell Registrar Cue Cell Finder (PostCR_CueCellFinder)","text":""},{"location":"CLIs/unitAnalysis/#pcrccf-input","title":"PCRCCF Input","text":"<ul> <li>multSessSegStruc</li> </ul>"},{"location":"CLIs/unitAnalysis/#pcrccf-output","title":"PCRCCF Output","text":"<ul> <li>PCRTrigSigDict<ul> <li>Figures per subject (/path/to/multSessSegStruc/Figures)</li> <li>Figures across subjects (/path/to/MultSess/dir/~GroupData)</li> </ul> </li> </ul>"},{"location":"CLIs/unitAnalysis/#pcrcff-cli","title":"PCRCFF CLI","text":"<pre><code>usage: PostCR_CueCellFinder.py  [-h] [-p PATH] [-s2p SESS2PROCESS] [-ots OUTLIER_TS]\n                                [-sf SESSFOCUS] [-4p FORPRES]\n\nRun Post CellRegistrar Cue Cell Finder with command line arguments.\n\noptions:\n  -h, --help            show this help message and exit\n  -p PATH, --path PATH  Path to the data directory (e.g. /path/to/data).\n                        Default will prompt user to choose path.\n                        NOTE: Pick directory which holds session folders.\n                              Do not pick/set a session folder.\n  -s2p SESS2PROCESS, --sess2process SESS2PROCESS\n                        List of sessions to process. Write in format '1,2,3', '1-3',\n                        or '1,2-5' to select by specific session number.\n                        Input all or ALL to process all eligible sessions that are\n                        available within the set path.\n                        Default will prompt user to choose.\n  -ots OUTLIER_TS, --outlier_ts OUTLIER_TS\n                        Outlier threshold to filter out meanTrigSig by group where\n                        mean value exceeds threshold set here.\n                        Default is 10^2.\n  -sf SESSFOCUS, --sessFocus SESSFOCUS\n                        Select number of sessions to plot. Default is None, which plots\n                        all sessions\n  -4p FORPRES, --forPres FORPRES\n                        Whether to export .svg for figures in addition to the usual\n                        png output. Default is False.\n  -pit PLOTINDTRIGSIG, --plotIndTrigSig PLOTINDTRIGSIG\n                        Whether to plot individual TrigSig by subjected ID. Default is True.\n</code></pre>"},{"location":"GUIs/CROPPER/","title":"1Photon Cropping Utility","text":""},{"location":"GUIs/CROPPER/#web-app","title":"Web App","text":"<p>A web-based utility for cropping 1-photon imaging data (.isxd files) before processing. Built with FastAPI backend and React frontend.</p>"},{"location":"GUIs/CROPPER/#features","title":"Features","text":"<ul> <li>Interactive cropping interface for ISXD files</li> <li>Real-time frame preview</li> <li>Directory navigation and file management</li> <li>Auto import cropping dimensions if cropping was done previously</li> </ul>"},{"location":"GUIs/CROPPER/#output","title":"Output","text":"<ul> <li><code>crop_dims.json</code>: JSON file containing crop coordinates<ul> <li>Format: <code>[(x1, y1), (x2, y2)]</code></li> <li>Saved in the same directory as the ISXD file</li> </ul> </li> </ul>"},{"location":"GUIs/CROPPER/#access","title":"Access","text":"<p>The web app can be accessed at: <code>http://[server-address]:[port]</code>. Based on what is in Application settings, the default port is <code>8001</code>.</p>"},{"location":"GUIs/GUI_index/","title":"GUI Tools","text":"<p>This directory contains documentation for the various GUI tools available in CLAH Image Analysis.</p>"},{"location":"GUIs/GUI_index/#available-guis","title":"Available GUIs","text":""},{"location":"GUIs/GUI_index/#motion-correction-gui","title":"Motion Correction GUI","text":"<p>A graphical interface to create jobs to run motion correcting and/or segmentation tasks of calcium imaging data. Provides tools for:</p> <ul> <li>Motion correction parameter adjustment</li> <li>Real-time preview of correction results</li> <li>Batch processing capabilities</li> </ul>"},{"location":"GUIs/GUI_index/#segdict-utility","title":"SegDict Utility","text":"<p>A web-based interface for viewing and evaluating segments from the segDict. Features include:</p> <ul> <li>Component evaluation and classification</li> <li>Spatial and temporal visualization</li> <li>Neural network integration</li> <li>Export capabilities</li> </ul>"},{"location":"GUIs/GUI_index/#1p-cropping-utility","title":"1P Cropping Utility","text":"<p>A web-based utility for cropping 1-photon imaging data (.isxd files) before processing.</p>"},{"location":"GUIs/GUI_index/#access","title":"Access","text":"<p>All web-based GUIs can be accessed through your server at their respective ports. Default ports are configured in Application settings.</p>"},{"location":"GUIs/MOCOGUI/","title":"Motion Correction &amp; Segmentation (GUI)","text":""},{"location":"GUIs/MOCOGUI/#web-app","title":"Web App","text":"<p>The M2SD Web App provides a streamlined interface for running motion correction and segmentation analysis on imaging data. The app is built using Streamlit and can be run as a system service for continuous availability.</p>"},{"location":"GUIs/MOCOGUI/#requirements","title":"Requirements","text":"<ul> <li>configured SQLJobScheduler</li> <li>System service setup (via systemd)</li> <li>a port available for web access</li> </ul>"},{"location":"GUIs/MOCOGUI/#key-features","title":"Key Features","text":"<ul> <li>Path Search &amp; Selection: Easily search and select data paths from a SQLite database cache</li> <li>Session Processing: Choose to process all sessions or select specific ones</li> <li>Main Options:<ul> <li>Motion Correction (MC)</li> <li>Segmentation (SG)</li> <li>Overwrite existing files</li> </ul> </li> <li>Advanced Settings:<ul> <li>Concatenate files</li> <li>Compute metrics</li> <li>Export post-segmentation residuals</li> <li>Handle separate channels</li> <li>Motion correction iterations</li> </ul> </li> </ul>"},{"location":"GUIs/MOCOGUI/#job-scheduling-system","title":"Job Scheduling System","text":"<p>The app uses SQL Job Scheduler to manage analysis tasks:</p> <ol> <li>Job Queue: When analysis is initiated, jobs are added to a SQL-based queue</li> <li>Email Notifications: Users must provide an email address to receive notifications about:</li> <li>Job start</li> <li>Analysis progress</li> <li>Completion status</li> <li>Any errors encountered</li> </ol>"},{"location":"GUIs/MOCOGUI/#access","title":"Access","text":"<p>The web app can be accessed at: <code>http://[server-address]:[port]/m2sd</code>. Based on what is in Application settings, the default port is <code>8503</code>.</p>"},{"location":"GUIs/MOCOGUI/#usage-flow","title":"Usage Flow","text":"<ol> <li>Create or refresh database of eligible paths for analysis</li> <li>Search and select sessions to analyze</li> <li>Choose sessions to process</li> <li>Configure analysis options</li> <li>Click \"Run Analysis\" to queue jobs</li> <li>Monitor progress via email notifications</li> </ol>"},{"location":"GUIs/SDGUI/","title":"SegDict Utility (GUI)","text":""},{"location":"GUIs/SDGUI/#web-app","title":"Web App","text":"<p>The SegDict Utility web app provides a way to view and evaluate segments saved in the segDict that result after running Motion Correction and Segmentation.</p>"},{"location":"GUIs/SDGUI/#requirements","title":"Requirements","text":"<ul> <li>System service setup (via systemd)</li> <li>A port available for web access</li> </ul>"},{"location":"GUIs/SDGUI/#key-features","title":"Key Features","text":""},{"location":"GUIs/SDGUI/#component-evaluation","title":"Component Evaluation","text":"<ul> <li>View and evaluate individual components from the segDict</li> <li>Accept/reject/undecided classification for each component</li> <li>Multiple evaluation methods:<ul> <li>CNMF Component Evaluation</li> <li>Accepted Labels from segDict (ISX)</li> <li>Neural Network Component Evaluation</li> <li>Previously Done Accepted/Rejected Components</li> </ul> </li> </ul>"},{"location":"GUIs/SDGUI/#visualization-tools","title":"Visualization Tools","text":"<ul> <li> <p>Spatial Profile View:</p> <ul> <li>Display component spatial footprints</li> <li>Toggle cell number overlay</li> <li>Show all components or only accepted ones</li> <li>Multiple colormap options</li> <li>Integration with downsampled images</li> </ul> </li> <li> <p>Temporal Profile View:</p> <ul> <li>Display calcium signals for each component</li> <li>Peak detection with two algorithms:<ul> <li>Scipy-based peak detection</li> <li>Iterative differences method</li> </ul> </li> <li>Signal processing options:<ul> <li>Baseline adjustment</li> <li>Smoothing via Savitzky-Golay filter</li> <li>Spike deconvolution visualization</li> </ul> </li> <li>Peak transient profile analysis</li> </ul> </li> </ul>"},{"location":"GUIs/SDGUI/#neural-network-integration","title":"Neural Network Integration","text":"<ul> <li>Model Training:<ul> <li>Add sessions to training set</li> <li>Train new models with optimized hyperparameters</li> <li>Cross-validation performance metrics</li> </ul> </li> <li>Model Management:<ul> <li>Save trained models</li> <li>Load existing models</li> <li>Evaluate components using trained models</li> </ul> </li> </ul>"},{"location":"GUIs/SDGUI/#export-capabilities","title":"Export Capabilities","text":"<ul> <li>Component Selection Export:<ul> <li>Save accepted/rejected/undecided components as JSON</li> <li>Preview export data</li> </ul> </li> <li>Peaks Dictionary Export:<ul> <li>Save peak detection parameters and results</li> <li>Include baseline and smoothing settings</li> <li>Preview peak data</li> </ul> </li> </ul>"},{"location":"GUIs/SDGUI/#access","title":"Access","text":"<p>The web app can be accessed at <code>http://[server-address]:[port]/segdict</code>. Based on what is in Application settings, the default port is <code>8504</code>.</p>"},{"location":"GUIs/SDGUI/#usage","title":"Usage","text":"<ol> <li>Session Selection</li> <li>Search and select a session containing segDict files</li> <li> <p>View session details and component counts</p> </li> <li> <p>Component Evaluation</p> </li> <li>Select components using the ROI selector</li> <li>Classify components as accepted/rejected/undecided</li> <li> <p>Use existing evaluations or create new ones</p> </li> <li> <p>Visualization</p> </li> <li>Toggle between spatial and temporal views</li> <li>Adjust visualization parameters</li> <li> <p>Analyze peak characteristics</p> </li> <li> <p>Export</p> </li> <li>Export component selections</li> <li>Export peak detection results</li> <li>Preview export data before saving</li> </ol>"}]}